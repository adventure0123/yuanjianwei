---
title: bitmap
date: 2016-07-22 22:37:43
tags: [bitmap,bloom filter]
---
&emsp;&emsp;问题：如何防止用户恶意刷商品的关注数。假设现在有1000个商品，每一个商品都有几万人关注，最坏情况每个商品有1000W人关注。每个用户可以关注或者取消某个商品。<!--more-->商品的有效期是一天，每过一天商品都会换另一批。现在的做法是在redis中使用hash来保存商品的关注数，主键是日期，field是商品的skuid，value是用户的关注数量，主键的过期日期是24小时。这样做的好处是不用储存用户的信息，省redis内存，占用带宽少，操作速度快。但也导致了一个问题，有一部分人恶意刷高或者刷少某个商品的关注数。因为无法验证关注或者取消请求的合法性，导致不能杜绝用户的刷关注行为。
&emsp;&emsp;为了解决这个问题，我们需要退出一个防刷功能。第一个方案是把用户的唯一标示记录下来。用户的每个请求都会带一个40字节的uuid，标示用户的信息。假设我们使用redis的set结构，key是商品的skuid,value是用户的uuid.如果用户对某个商品进行关注，首先查看set中是否有用户的uuid，如果没有则关注成功，将用户的uuid加入set中，如果set中已经有了用户的uuid则说明用户已经关注了，关注不成功。当用户取消的时候，进行相同的逻辑。这个方法能够从根本上解决用户恶意刷评论的行为，该方法对小数据量非常的有效，但是如果用户量上升将会导致占用大量的内存。例如每个商品关注的用户是1000W，总共1000个商品，将会占用：40*100000000*1000/1024/1024/1024=372.5G,占用了太多的内存，而且对服务器的带宽也是一个很大的压力。
&emsp;&emsp;因为用户的关注数不一定严格要求不能有任何误差，因此我们可以考虑用布隆过滤器。bloom filter是一种空间效率很高的随机数据结构，它可以看做是bitmap的扩展，它的主要原理是：当一个元素被加入时，首先通过K个hash函数将元素映射成位阵列的k个点，并置为1.当检索时，同样将被检索的元素映射为k个点。如果有其中一个点为0，则说明元素不在集合中。如果所有的k个点都为1，则说明有很大的概率元素存在集合中。布隆过滤器的示意图如下：
![docker](../../../../img/bloom filter.png)
{z,y,z}是一个集合，彩色的线表示集合中的每一个元素都被映射到bit数组的多个位上。元素w不在集合中，因为他被映射到的bit数组中存在0。布隆过滤器的优点是空间效率和查询效率都远远超过一般的算法，布隆过滤器的插入和查询的时间复杂度都是O(k),另外散列函数之间没有联系，方便硬件实现。布隆过滤器本生不保存密码，适用于一些对安全性有较高要求的应用。但布隆过滤器也存在以下一些缺点：随着插入元素的增加，误差率也随之增加。另一方面，布隆过滤器不支持从集合中删除元素。为了实现从集合中删除元素，我们可以使用布隆过滤器的变种，counter bloom filter.counter bloomfilter是将布隆过滤器的每一位扩展成一个小的计数器，在插入时，分别对k位加1，删除时则分别减1.counter bloom filter通过占用几倍的存储空间，解决了布隆过滤器的删除问题。布隆过滤器通过只占哈希表的1/4到1/8的空间，就能解决相同的问题。在这个实际使用中，我们使用counter bloom filter，在1000W关注数，并且误差在0.1%左右时，使用的空间大约降低了一倍。
&emsp;&emsp;为了进一步降低内存，我们可以采用bitmap来存储用户的信息。首先使用hash函数，将用户的uuid映射为一个32位的正整数,同时初始化一个长度为2^32次方长度的bitmap,bitmap的每一位对应用户的一个id.当用户关注则将bitmap相应的位数置1，取消关注则置为0.通过redis,我们可以方便的使用bitset和getbit操作和查询bitmap的每一位。2^32次方长度的bitmap大约占用16M的内存，因此我们只需要大约16G的内存，并且冲突在百分之零点几的情况下就完美的解决了问题，同时也大大的减少了带宽的使用。在实际使用中，因为商品的关注人数一般只有几万到十几万的规模，因此我们综合考虑只使用hash之后32位整数的中间24位，在插入在几万的情况下，冲突大约为百分之0.3，在插入在100W的情况下冲突为百分之1.2，基本满足了我们的需求。这次通过实际问题，综合考虑内存，误差和带宽，比较了多种解决方案的优劣，最后较为圆满的解决了问题，因为把这个解决过程记录下来，供后来的人参考。
